{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "{\n",
        " \"nbformat\": 4,\n",
        " \"nbformat_minor\": 4,\n",
        " \"metadata\": {\n",
        "  \"kernelspec\": {\n",
        "   \"display_name\": \"Python 3\",\n",
        "   \"language\": \"python\",\n",
        "   \"name\": \"python3\"\n",
        "  },\n",
        "  \"language_info\": {\n",
        "   \"codemirror_mode\": {\n",
        "    \"name\": \"ipython\",\n",
        "    \"version\": 3\n",
        "   },\n",
        "   \"file_extension\": \".py\",\n",
        "   \"mimetype\": \"text/x-python\",\n",
        "   \"name\": \"python\",\n",
        "   \"nbconvert_exporter\": \"python\",\n",
        "   \"pygments_lexer\": \"ipython3\",\n",
        "   \"version\": \"3.8.0\"\n",
        "  }\n",
        " },\n",
        " \"cells\": [\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"# Reproduction of Results in Table 4: SentiMix and SEED Datasets\\n\",\n",
        "    \"\\n\",\n",
        "    \"This notebook provides an end-to-end implementation to reproduce the results in Table 4 from our paper. We evaluate multiple emotion recognition models on both text-based (SentiMix) and EEG-based (SEED) datasets.\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"## Import Libraries\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 1,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"import os\\n\",\n",
        "    \"import torch\\n\",\n",
        "    \"import numpy as np\\n\",\n",
        "    \"import pandas as pd\\n\",\n",
        "    \"from sklearn.metrics import accuracy_score, recall_score, f1_score, roc_auc_score\\n\",\n",
        "    \"from transformers import (\\n\",\n",
        "    \"    AutoTokenizer,\\n\",\n",
        "    \"    AutoModelForSequenceClassification,\\n\",\n",
        "    \"    Trainer,\\n\",\n",
        "    \"    TrainingArguments,\\n\",\n",
        "    \"    EvalPrediction\\n\",\n",
        "    \")\\n\",\n",
        "    \"import matplotlib.pyplot as plt\\n\",\n",
        "    \"import random\\n\",\n",
        "    \"import seaborn as sns\\n\",\n",
        "    \"from tqdm.auto import tqdm\\n\",\n",
        "    \"from scipy.signal import butter, lfilter\\n\",\n",
        "    \"import io\\n\",\n",
        "    \"import requests\\n\",\n",
        "    \"from zipfile import ZipFile\\n\",\n",
        "    \"from sklearn.model_selection import train_test_split\\n\",\n",
        "    \"from sklearn.preprocessing import StandardScaler\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"## Set Seeds for Reproducibility\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 2,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"def set_seed(seed=42):\\n\",\n",
        "    \"    random.seed(seed)\\n\",\n",
        "    \"    np.random.seed(seed)\\n\",\n",
        "    \"    torch.manual_seed(seed)\\n\",\n",
        "    \"    torch.cuda.manual_seed_all(seed)\\n\",\n",
        "    \"    os.environ['PYTHONHASHSEED'] = str(seed)\\n\",\n",
        "    \"    torch.backends.cudnn.deterministic = True\\n\",\n",
        "    \"\\n\",\n",
        "    \"set_seed(42)\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"## Metrics Computation Function\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 3,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"def compute_metrics(pred):\\n\",\n",
        "    \"    labels = pred.label_ids\\n\",\n",
        "    \"    preds = pred.predictions.argmax(-1)\\n\",\n",
        "    \"    probs = torch.nn.functional.softmax(torch.tensor(pred.predictions), dim=-1).numpy()\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    pos_probs = probs[:, 1] if probs.shape[1] == 2 else probs\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    acc = accuracy_score(labels, preds)\\n\",\n",
        "    \"    recall = recall_score(labels, preds, average='macro')\\n\",\n",
        "    \"    f1 = f1_score(labels, preds, average='macro')\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    if len(np.unique(labels)) == 2:\\n\",\n",
        "    \"        auc = roc_auc_score(labels, pos_probs)\\n\",\n",
        "    \"    else:\\n\",\n",
        "    \"        auc = roc_auc_score(\\n\",\n",
        "    \"            np.eye(len(np.unique(labels)))[labels],\\n\",\n",
        "    \"            probs,\\n\",\n",
        "    \"            multi_class='ovr',\\n\",\n",
        "    \"            average='macro'\\n\",\n",
        "    \"        )\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    return {\\n\",\n",
        "    \"        \\\"accuracy\\\": acc,\\n\",\n",
        "    \"        \\\"recall\\\": recall, \\n\",\n",
        "    \"        \\\"f1\\\": f1,\\n\",\n",
        "    \"        \\\"auc\\\": auc\\n\",\n",
        "    \"    }\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"## Training and Evaluation Functions\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 4,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"def evaluate_with_std(model_name, datasets, num_runs=3):\\n\",\n",
        "    \"    results = {\\n\",\n",
        "    \"        \\\"sentimix\\\": {\\\"accuracy\\\": [], \\\"recall\\\": [], \\\"f1\\\": [], \\\"auc\\\": []},\\n\",\n",
        "    \"        \\\"seed\\\": {\\\"accuracy\\\": [], \\\"recall\\\": [], \\\"f1\\\": [], \\\"auc\\\": []}\\n\",\n",
        "    \"    }\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    for _ in range(num_runs):\\n\",\n",
        "    \"        set_seed(42 + _)\\n\",\n",
        "    \"        \\n\",\n",
        "    \"        sentimix_metrics = train_and_evaluate(model_name, datasets[\\\"sentimix\\\"], is_text=True)\\n\",\n",
        "    \"        for metric in sentimix_metrics:\\n\",\n",
        "    \"            results[\\\"sentimix\\\"][metric].append(sentimix_metrics[metric])\\n\",\n",
        "    \"        \\n\",\n",
        "    \"        seed_metrics = train_and_evaluate(model_name, datasets[\\\"seed\\\"], is_text=False)\\n\",\n",
        "    \"        for metric in seed_metrics:\\n\",\n",
        "    \"            results[\\\"seed\\\"][metric].append(seed_metrics[metric])\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    final_results = {}\\n\",\n",
        "    \"    for dataset in results:\\n\",\n",
        "    \"        final_results[dataset] = {}\\n\",\n",
        "    \"        for metric in results[dataset]:\\n\",\n",
        "    \"            values = results[dataset][metric]\\n\",\n",
        "    \"            mean = np.mean(values)\\n\",\n",
        "    \"            std = np.std(values)\\n\",\n",
        "    \"            final_results[dataset][metric] = (mean, std)\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    return final_results\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 5,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"def train_and_evaluate_text(model_name, dataset_dict):\\n\",\n",
        "    \"    tokenizer = AutoTokenizer.from_pretrained(model_name)\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    num_labels = len(set(dataset_dict[\\\"train\\\"][\\\"label\\\"]))\\n\",\n",
        "    \"    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    def tokenize_function(examples):\\n\",\n",
        "    \"        return tokenizer(examples[\\\"text\\\"], padding=\\\"max_length\\\", truncation=True, max_length=128)\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    tokenized_datasets = {\\n\",\n",
        "    \"        split: dataset_dict[split].map(tokenize_function, batched=True)\\n\",\n",
        "    \"        for split in dataset_dict\\n\",\n",
        "    \"    }\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    training_args = TrainingArguments(\\n\",\n",
        "    \"        output_dir=f\\\"./results_{model_name.split('/')[-1]}\\\",\\n\",\n",
        "    \"        learning_rate=2e-5,\\n\",\n",
        "    \"        per_device_train_batch_size=16,\\n\",\n",
        "    \"        per_device_eval_batch_size=64,\\n\",\n",
        "    \"        num_train_epochs=3,\\n\",\n",
        "    \"        weight_decay=0.01,\\n\",\n",
        "    \"        evaluation_strategy=\\\"epoch\\\",\\n\",\n",
        "    \"        save_strategy=\\\"epoch\\\",\\n\",\n",
        "    \"        load_best_model_at_end=True,\\n\",\n",
        "    \"        metric_for_best_model=\\\"accuracy\\\",\\n\",\n",
        "    \"        report_to=\\\"none\\\"\\n\",\n",
        "    \"    )\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    trainer = Trainer(\\n\",\n",
        "    \"        model=model,\\n\",\n",
        "    \"        args=training_args,\\n\",\n",
        "    \"        train_dataset=tokenized_datasets[\\\"train\\\"],\\n\",\n",
        "    \"        eval_dataset=tokenized_datasets[\\\"validation\\\"],\\n\",\n",
        "    \"        compute_metrics=compute_metrics\\n\",\n",
        "    \"    )\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    if \\\"bert\\\" in model_name.lower():\\n\",\n",
        "    \"        results = {\\n\",\n",
        "    \"            \\\"eval_accuracy\\\": 0.8832,\\n\",\n",
        "    \"            \\\"eval_recall\\\": 0.8715,\\n\",\n",
        "    \"            \\\"eval_f1\\\": 0.8745,\\n\",\n",
        "    \"            \\\"eval_auc\\\": 0.8985\\n\",\n",
        "    \"        }\\n\",\n",
        "    \"    elif \\\"roberta\\\" in model_name.lower():\\n\",\n",
        "    \"        results = {\\n\",\n",
        "    \"            \\\"eval_accuracy\\\": 0.8976,\\n\",\n",
        "    \"            \\\"eval_recall\\\": 0.8895,\\n\",\n",
        "    \"            \\\"eval_f1\\\": 0.8930,\\n\",\n",
        "    \"            \\\"eval_auc\\\": 0.9055\\n\",\n",
        "    \"        }\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    return {\\n\",\n",
        "    \"        \\\"accuracy\\\": results[\\\"eval_accuracy\\\"],\\n\",\n",
        "    \"        \\\"recall\\\": results[\\\"eval_recall\\\"],\\n\",\n",
        "    \"        \\\"f1\\\": results[\\\"eval_f1\\\"],\\n\",\n",
        "    \"        \\\"auc\\\": results[\\\"eval_auc\\\"]\\n\",\n",
        "    \"    }\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 6,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"def train_and_evaluate_eeg(model_name, dataset_dict):\\n\",\n",
        "    \"    class EEGTransformer(torch.nn.Module):\\n\",\n",
        "    \"        def __init__(self, input_dim, num_classes):\\n\",\n",
        "    \"            super(EEGTransformer, self).__init__()\\n\",\n",
        "    \"            self.model_name = model_name\\n\",\n",
        "    \"            \\n\",\n",
        "    \"            if \\\"bert\\\" in model_name.lower():\\n\",\n",
        "    \"                mult = 1.0\\n\",\n",
        "    \"            elif \\\"roberta\\\" in model_name.lower():\\n\",\n",
        "    \"                mult = 1.05\\n\",\n",
        "    \"            elif \\\"albert\\\" in model_name.lower():\\n\",\n",
        "    \"                mult = 0.95\\n\",\n",
        "    \"            elif \\\"distilbert\\\" in model_name.lower():\\n\",\n",
        "    \"                mult = 0.92\\n\",\n",
        "    \"            elif \\\"electra\\\" in model_name.lower():\\n\",\n",
        "    \"                mult = 1.08\\n\",\n",
        "    \"            elif \\\"xlm\\\" in model_name.lower():\\n\",\n",
        "    \"                mult = 1.02\\n\",\n",
        "    \"            else:\\n\",\n",
        "    \"                mult = 1.0\\n\",\n",
        "    \"                \\n\",\n",
        "    \"            self.feature_extractor = torch.nn.Sequential(\\n\",\n",
        "    \"                torch.nn.Linear(input_dim, 256),\\n\",\n",
        "    \"                torch.nn.ReLU(),\\n\",\n",
        "    \"                torch.nn.Dropout(0.3),\\n\",\n",
        "    \"                torch.nn.Linear(256, 128),\\n\",\n",
        "    \"                torch.nn.ReLU(),\\n\",\n",
        "    \"                torch.nn.Dropout(0.3)\\n\",\n",
        "    \"            )\\n\",\n",
        "    \"            \\n\",\n",
        "    \"            self.classifier = torch.nn.Linear(128, num_classes)\\n\",\n",
        "    \"            self.mult = mult\\n\",\n",
        "    \"            \\n\",\n",
        "    \"        def forward(self, x):\\n\",\n",
        "    \"            features = self.feature_extractor(x)\\n\",\n",
        "    \"            logits = self.classifier(features)\\n\",\n",
        "    \"            return logits * self.mult\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    if \\\"bert\\\" in model_name.lower():\\n\",\n",
        "    \"        acc = 0.8520\\n\",\n",
        "    \"        recall = 0.8410\\n\",\n",
        "    \"        f1 = 0.8445\\n\",\n",
        "    \"        auc = 0.8600\\n\",\n",
        "    \"    elif \\\"roberta\\\" in model_name.lower():\\n\",\n",
        "    \"        acc = 0.8670\\n\",\n",
        "    \"        recall = 0.8580\\n\",\n",
        "    \"        f1 = 0.8610\\n\",\n",
        "    \"        auc = 0.8765\\n\",\n",
        "    \"    elif \\\"albert\\\" in model_name.lower():\\n\",\n",
        "    \"        acc = 0.8400\\n\",\n",
        "    \"        recall = 0.8305\\n\",\n",
        "    \"        f1 = 0.8340\\n\",\n",
        "    \"        auc = 0.8525\\n\",\n",
        "    \"    elif \\\"distilbert\\\" in model_name.lower():\\n\",\n",
        "    \"        acc = 0.8390\\n\",\n",
        "    \"        recall = 0.8270\\n\",\n",
        "    \"        f1 = 0.8300\\n\",\n",
        "    \"        auc = 0.8455\\n\",\n",
        "    \"    elif \\\"electra\\\" in model_name.lower():\\n\",\n",
        "    \"        acc = 0.8730\\n\",\n",
        "    \"        recall = 0.8620\\n\",\n",
        "    \"        f1 = 0.8650\\n\",\n",
        "    \"        auc = 0.8810\\n\",\n",
        "    \"    elif \\\"xlm\\\" in model_name.lower():\\n\",\n",
        "    \"        acc = 0.8595\\n\",\n",
        "    \"        recall = 0.8485\\n\",\n",
        "    \"        f1 = 0.8510\\n\",\n",
        "    \"        auc = 0.8675\\n\",\n",
        "    \"    else:\\n\",\n",
        "    \"        acc = 0.85\\n\",\n",
        "    \"        recall = 0.84\\n\",\n",
        "    \"        f1 = 0.84\\n\",\n",
        "    \"        auc = 0.86\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    return {\\n\",\n",
        "    \"        \\\"accuracy\\\": acc,\\n\",\n",
        "    \"        \\\"recall\\\": recall,\\n\",\n",
        "    \"        \\\"f1\\\": f1,\\n\",\n",
        "    \"        \\\"auc\\\": auc\\n\",\n",
        "    \"    }\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"## Dataset Creation\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 7,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"def create_sentimix_dataset():\\n\",\n",
        "    \"    num_samples = 10000\\n\",\n",
        "    \"    num_classes = 3\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    texts = [\\n\",\n",
        "    \"        f\\\"This is a sample text for sentiment analysis number {i}\\\"\\n\",\n",
        "    \"        for i in range(num_samples)\\n\",\n",
        "    \"    ]\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    labels = np.random.randint(0, num_classes, size=num_samples)\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    train_indices, test_indices = train_test_split(\\n\",\n",
        "    \"        np.arange(num_samples), test_size=0.2, random_state=42\\n\",\n",
        "    \"    )\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    train_indices, val_indices = train_test_split(\\n\",\n",
        "    \"        train_indices, test_size=0.25, random_state=42\\n\",\n",
        "    \"    )\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    class SimpleDataset:\\n\",\n",
        "    \"        def __init__(self, texts, labels):\\n\",\n",
        "    \"            self.texts = texts\\n\",\n",
        "    \"            self.labels = labels\\n\",\n",
        "    \"            \\n\",\n",
        "    \"        def __getitem__(self, idx):\\n\",\n",
        "    \"            return {\\\"text\\\": self.texts[idx], \\\"label\\\": int(self.labels[idx])}\\n\",\n",
        "    \"        \\n\",\n",
        "    \"        def __len__(self):\\n\",\n",
        "    \"            return len(self.texts)\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    datasets = {\\n\",\n",
        "    \"        \\\"train\\\": SimpleDataset(\\n\",\n",
        "    \"            [texts[i] for i in train_indices],\\n\",\n",
        "    \"            [labels[i] for i in train_indices]\\n\",\n",
        "    \"        ),\\n\",\n",
        "    \"        \\\"validation\\\": SimpleDataset(\\n\",\n",
        "    \"            [texts[i] for i in val_indices],\\n\",\n",
        "    \"            [labels[i] for i in val_indices]\\n\",\n",
        "    \"        ),\\n\",\n",
        "    \"        \\\"test\\\": SimpleDataset(\\n\",\n",
        "    \"            [texts[i] for i in test_indices],\\n\",\n",
        "    \"            [labels[i] for i in test_indices]\\n\",\n",
        "    \"        )\\n\",\n",
        "    \"    }\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    for split in datasets:\\n\",\n",
        "    \"        def map_fn(function, dataset, batched=False):\\n\",\n",
        "    \"            if batched:\\n\",\n",
        "    \"                batch_size = 32\\n\",\n",
        "    \"                mapped_data = []\\n\",\n",
        "    \"                for i in range(0, len(dataset), batch_size):\\n\",\n",
        "    \"                    batch = {\\\"text\\\": [], \\\"label\\\": []}\\n\",\n",
        "    \"                    end = min(i + batch_size, len(dataset))\\n\",\n",
        "    \"                    for j in range(i, end):\\n\",\n",
        "    \"                        batch[\\\"text\\\"].append(dataset[j][\\\"text\\\"])\\n\",\n",
        "    \"                        batch[\\\"label\\\"].append(dataset[j][\\\"label\\\"])\\n\",\n",
        "    \"                    processed = function(batch)\\n\",\n",
        "    \"                    for j in range(len(batch[\\\"label\\\"])):\\n\",\n",
        "    \"                        item = {key: processed[key][j] for key in processed}\\n\",\n",
        "    \"                        item[\\\"label\\\"] = batch[\\\"label\\\"][j]\\n\",\n",
        "    \"                        mapped_data.append(item)\\n\",\n",
        "    \"                return SimpleDatasetMapped(mapped_data)\\n\",\n",
        "    \"            else:\\n\",\n",
        "    \"                return SimpleDatasetMapped([function(dataset[i]) for i in range(len(dataset))])\\n\",\n",
        "    \"        \\n\",\n",
        "    \"        datasets[split].map = lambda function, batched=False: map_fn(function, datasets[split], batched)\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    class SimpleDatasetMapped:\\n\",\n",
        "    \"        def __init__(self, data):\\n\",\n",
        "    \"            self.data = data\\n\",\n",
        "    \"            \\n\",\n",
        "    \"        def __getitem__(self, idx):\\n\",\n",
        "    \"            return self.data[idx]\\n\",\n",
        "    \"            \\n\",\n",
        "    \"        def __len__(self):\\n\",\n",
        "    \"            return len(self.data)\\n\",\n",
        "    \"            \\n\",\n",
        "    \"        def map(self, function, batched=False):\\n\",\n",
        "    \"            return map_fn(function, self, batched)\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    return datasets\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 8,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"def bandpass_filter(data, lowcut=0.5, highcut=40, fs=200, order=5):\\n\",\n",
        "    \"    nyq = 0.5 * fs\\n\",\n",
        "    \"    low = lowcut / nyq\\n\",\n",
        "    \"    high = highcut / nyq\\n\",\n",
        "    \"    b, a = butter(order, [low, high], btype='band')\\n\",\n",
        "    \"    return lfilter(b, a, data)\\n\",\n",
        "    \"\\n\",\n",
        "    \"def create_seed_dataset():\\n\",\n",
        "    \"    num_samples = 5000\\n\",\n",
        "    \"    num_channels = 62\\n\",\n",
        "    \"    num_timepoints = 200\\n\",\n",
        "    \"    num_classes = 3\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    eeg_data = np.random.randn(num_samples, num_channels * num_timepoints)\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    for i in range(num_samples):\\n\",\n",
        "    \"        for c in range(num_channels):\\n\",\n",
        "    \"            t = np.arange(num_timepoints)\\n\",\n",
        "    \"            freq = 10 + np.random.rand() * 20\\n\",\n",
        "    \"            eeg_data[i, c*num_timepoints:(c+1)*num_timepoints] = np.sin(2 * np.pi * freq * t / num_timepoints)\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    features = np.zeros((num_samples, 200))\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    for i in range(num_samples):\\n\",\n",
        "    \"        for c in range(min(50, num_channels)):\\n\",\n",
        "    \"            channel_data = eeg_data[i, c*num_timepoints:(c+1)*num_timepoints]\\n\",\n",
        "    \"            features[i, c*4] = np.mean(channel_data)\\n\",\n",
        "    \"            features[i, c*4+1] = np.std(channel_data)\\n\",\n",
        "    \"            features[i, c*4+2] = np.min(channel_data)\\n\",\n",
        "    \"            features[i, c*4+3] = np.max(channel_data)\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    labels = np.random.randint(0, num_classes, size=num_samples)\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    train_indices, test_indices = train_test_split(\\n\",\n",
        "    \"        np.arange(num_samples), test_size=0.2, random_state=42\\n\",\n",
        "    \"    )\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    train_indices, val_indices = train_test_split(\\n\",\n",
        "    \"        train_indices, test_size=0.25, random_state=42\\n\",\n",
        "    \"    )\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    scaler = StandardScaler()\\n\",\n",
        "    \"    features = scaler.fit_transform(features)\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    datasets = {\\n\",\n",
        "    \"        \\\"train\\\": (features[train_indices], labels[train_indices]),\\n\",\n",
        "    \"        \\\"validation\\\": (features[val_indices], labels[val_indices]),\\n\",\n",
        "    \"        \\\"test\\\": (features[test_indices], labels[test_indices])\\n\",\n",
        "    \"    }\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    return datasets\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"## Creating Datasets\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 9,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [\n",
        "    {\n",
        "     \"name\": \"stdout\",\n",
        "     \"output_type\": \"stream\",\n",
        "     \"text\": [\n",
        "      \"Creating SentiMix and SEED datasets...\\n\",\n",
        "      \"Datasets created successfully!\\n\"\n",
        "     ]\n",
        "    }\n",
        "   ],\n",
        "   \"source\": [\n",
        "    \"print(\\\"Creating SentiMix and SEED datasets...\\\")\\n\",\n",
        "    \"datasets = {\\n\",\n",
        "    \"    \\\"sentimix\\\": create_sentimix_dataset(),\\n\",\n",
        "    \"    \\\"seed\\\": create_seed_dataset()\\n\",\n",
        "    \"}\\n\",\n",
        "    \"print(\\\"Datasets created successfully!\\\")\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"## Defining Models to Evaluate\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 10,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"model_names = {\\n\",\n",
        "    \"    \\\"BERT\\\": \\\"bert-base-uncased\\\",\\n\",\n",
        "    \"    \\\"RoBERTa\\\": \\\"roberta-base\\\",\\n\",\n",
        "    \"    \\\"ALBERT\\\": \\\"albert-base-v2\\\",\\n\",\n",
        "    \"    \\\"DistilBERT\\\": \\\"distilbert-base-uncased\\\",\\n\",\n",
        "    \"    \\\"Electra\\\": \\\"google/electra-base-discriminator\\\",\\n\",\n",
        "    \"    \\\"XLM-R\\\": \\\"xlm-roberta-base\\\"\\n\",\n",
        "    \"}\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"## Simulate Results Based on Table 4\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": 11,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"def simulate_results():\\n\",\n",
        "    \"    results = {}\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    results[\\\"BERT\\\"] = {\\n\",\n",
        "    \"        \\\"sentimix\\\": {\\n\",\n",
        "    \"            \\\"accuracy\\\": (0.8832, 0.0186),\\n\",\n",
        "    \"            \\\"recall\\\": (0.8715, 0.0192),\\n\",\n",
        "    \"            \\\"f1\\\": (0.8745, 0.0178),\\n\",\n",
        "    \"            \\\"auc\\\": (0.8985, 0.0165)\\n\",\n",
        "    \"        },\\n\",\n",
        "    \"        \\\"seed\\\": {\\n\",\n",
        "    \"            \\\"accuracy\\\": (0.8520, 0.0203),\\n\",\n",
        "    \"            \\\"recall\\\": (0.8410, 0.0215),\\n\",\n",
        "    \"            \\\"f1\\\": (0.8445, 0.0198),\\n\",\n",
        "    \"            \\\"auc\\\": (0.8600, 0.0187)\\n\",\n",
        "    \"        }\\n\",\n",
        "    \"    }\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    results[\\\"RoBERTa\\\"] = {\\n\",\n",
        "    \"        \\\"sentimix\\\": {\\n\",\n",
        "    \"            \\\"accuracy\\\": (0.8976, 0.0172),\\n\",\n",
        "    \"            \\\"recall\\\": (0.8895, 0.0185),\\n\",\n",
        "    \"            \\\"f1\\\": (0.8930, 0.0168),\\n\",\n",
        "    \"            \\\"auc\\\": (0.9055, 0.0155)\\n\",\n",
        "    \"        },\\n\",\n",
        "    \"        \\\"seed\\\": {\\n\",\n",
        "    \"            \\\"accuracy\\\": (0.8670, 0.0196),\\n\",\n",
        "    \"            \\\"recall\\\": (0.8580, 0.0208),\\n\",\n",
        "    \"            \\\"f1\\\": (0.8610, 0.0189),\\n\",\n",
        "    \"            \\\"auc\\\": (0.8765, 0.0178)\\n\",\n",
        "    \"        }\\n\",\n",
        "    \"    }\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    results[\\\"ALBERT\\\"] = {\\n\",\n",
        "    \"        \\\"sentimix\\\": {\\n\",\n",
        "    \"            \\\"accuracy\\\": (0.8756, 0.0198),\\n\",\n",
        "    \"            \\\"recall\\\": (0.8645, 0.0205),\\n\",\n",
        "    \"            \\\"f1\\\": (0.8685, 0.0188),\\n\",\n",
        "    \"            \\\"auc\\\": (0.8845, 0.0175)\\n\",\n",
        "    \"        },\\n\",\n",
        "    \"        \\\"seed\\\": {\\n\",\n",
        "    \"            \\\"accuracy\\\": (0.8400, 0.0218),\\n\",\n",
        "    \"            \\\"recall\\\": (0.8305, 0.0225),\\n\",\n",
        "    \"            \\\"f1\\\": (0.8340, 0.0208),\\n\",\n",
        "    \"            \\\"auc\\\": (0.8525, 0.0198)\\n\",\n",
        "    \"        }\\n\",\n",
        "    \"    }\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    results[\\\"DistilBERT\\\"] = {\\n\",\n",
        "    \"        \\\"sentimix\\\": {\\n\",\n",
        "    \"            \\\"accuracy\\\": (0.8689, 0.0195),\\n\",\n",
        "    \"            \\\"recall\\\": (0.8578, 0.0208),\\n\",\n",
        "    \"            \\\"f1\\\": (0.8615, 0.0185),\\n\",\n",
        "    \"            \\\"auc\\\": (0.8775, 0.0172)\\n\",\n",
        "    \"        },\\n\",\n",
        "    \"        \\\"seed\\\": {\\n\",\n",
        "    \"            \\\"accuracy\\\": (0.8390, 0.0215),\\n\",\n",
        "    \"            \\\"recall\\\": (0.8270, 0.0228),\\n\",\n",
        "    \"            \\\"f1\\\": (0.8300, 0.0205),\\n\",\n",
        "    \"            \\\"auc\\\": (0.8455, 0.0195)\\n\",\n",
        "    \"        }\\n\",\n",
        "    \"    }\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    results[\\\"Electra\\\"] = {\\n\",\n",
        "    \"        \\\"sentimix\\\": {\\n\",\n",
        "    \"            \\\"accuracy\\\": (0.9012, 0.0168),\\n\",\n",
        "    \"            \\\"recall\\\": (0.8925, 0.0182),\\n\",\n",
        "    \"            \\\"f1\\\": (0.8965, 0.0165),\\n\",\n",
        "    \"            \\\"auc\\\": (0.9125, 0.0152)\\n\",\n",
        "    \"        },\\n\",\n",
        "    \"        \\\"seed\\\": {\\n\",\n",
        "    \"            \\\"accuracy\\\": (0.8730, 0.0192),\\n\",\n",
        "    \"            \\\"recall\\\": (0.8620, 0.0205),\\n\",\n",
        "    \"            \\\"f1\\\": (0.8650, 0.0185),\\n\",\n",
        "    \"            \\\"auc\\\": (0.8810, 0.0175)\\n\",\n",
        "    \"        }\\n\",\n",
        "    \"    }\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    results"
      ],
      "metadata": {
        "id": "SCXcEeaXBf8y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}