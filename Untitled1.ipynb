{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "from sklearn.metrics import accuracy_score, recall_score, f1_score, roc_auc_score\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    EvalPrediction\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import seaborn as sns\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "DF8Pwctwss8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seeds for reproducibility\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# Function to compute metrics\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    probs = torch.nn.functional.softmax(torch.tensor(pred.predictions), dim=-1).numpy()\n",
        "\n",
        "    # For binary classification, we need positive class probabilities for AUC\n",
        "    pos_probs = probs[:, 1]\n",
        "\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    recall = recall_score(labels, preds, average='macro')\n",
        "    f1 = f1_score(labels, preds, average='macro')\n",
        "\n",
        "    # For AUC calculation, convert to one-hot if needed\n",
        "    if len(np.unique(labels)) == 2:\n",
        "        auc = roc_auc_score(labels, pos_probs)\n",
        "    else:\n",
        "        # For multiclass, use one-vs-rest approach\n",
        "        auc = roc_auc_score(\n",
        "            np.eye(len(np.unique(labels)))[labels],\n",
        "            probs,\n",
        "            multi_class='ovr',\n",
        "            average='macro'\n",
        "        )\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": acc,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1,\n",
        "        \"auc\": auc\n",
        "    }"
      ],
      "metadata": {
        "id": "CulKKT1Tstuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fdc4JMWAs7FQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}